# 后端技术关键词与实现指南

## 🎯 核心技术关键词

### Flask框架关键词
```
轻量级、灵活性、可扩展、微服务、Blueprint、中间件、装饰器、上下文
```

### 数据库设计关键词
```
关系型、ACID、事务、索引、查询优化、连接池、ORM、迁移、备份恢复
```

### API开发关键词
```
RESTful、HTTP协议、状态码、JSON、分页、筛选、排序、版本控制、文档化
```

### 任务调度关键词
```
异步执行、定时任务、cron表达式、并发控制、失败重试、状态管理、监控告警
```

### 安全性关键词
```
输入验证、SQL注入、XSS防护、CSRF保护、认证授权、加密存储、访问控制
```

### 性能优化关键词
```
缓存策略、连接池、查询优化、异步处理、负载均衡、资源监控、性能分析
```

## 🏗️ 详细实现提示词

### 1. Flask应用架构提示词

#### 应用工厂模式
```python
创建一个标准的Flask应用工厂：
- 使用create_app函数初始化应用
- 支持不同环境的配置管理
- 注册蓝图和中间件
- 配置错误处理器和日志系统
- 实现健康检查和监控接口
- 支持插件和扩展的动态加载
```

#### Blueprint模块化设计
```python
设计模块化的Blueprint架构：
- 按功能域划分Blueprint（spiders、files、logs等）
- 每个Blueprint独立的路由和错误处理
- 统一的请求响应格式
- 中间件处理认证、日志、跨域等
- 支持Blueprint的动态注册和卸载
- 实现Blueprint级别的权限控制
```

#### 中间件和装饰器
```python
实现功能丰富的中间件系统：
- 请求日志记录和性能监控
- 用户认证和权限验证
- 请求参数验证和格式化
- 响应数据压缩和缓存
- 异常捕获和错误处理
- 跨域资源共享(CORS)处理
```

### 2. 数据库设计提示词

#### 数据库连接管理
```python
实现高效的数据库连接管理：
- 使用上下文管理器自动管理连接
- 实现连接池减少连接开销
- 支持事务操作和回滚机制
- 实现读写分离和负载均衡
- 提供连接健康检查和自动重连
- 监控连接使用情况和性能
```

#### 数据访问层设计
```python
构建标准的数据访问层：
- 实现DAO模式封装数据操作
- 提供通用的CRUD操作接口
- 支持复杂查询和聚合操作
- 实现查询缓存和结果优化
- 提供批量操作和事务支持
- 实现数据验证和约束检查
```

#### 数据库表结构设计
```sql
设计合理的数据库表结构：
-- 爬虫表
CREATE TABLE spiders (
    id INTEGER PRIMARY KEY AUTOINCREMENT,
    name TEXT NOT NULL UNIQUE,
    description TEXT,
    code TEXT NOT NULL,
    status TEXT DEFAULT 'inactive',
    config TEXT DEFAULT '{}',
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    last_run_at TIMESTAMP,
    run_count INTEGER DEFAULT 0,
    success_count INTEGER DEFAULT 0,
    error_count INTEGER DEFAULT 0
);

-- 日志表
CREATE TABLE spider_logs (
    id INTEGER PRIMARY KEY AUTOINCREMENT,
    spider_id INTEGER NOT NULL,
    level TEXT NOT NULL,
    message TEXT NOT NULL,
    timestamp TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    source TEXT,
    execution_id TEXT,
    FOREIGN KEY (spider_id) REFERENCES spiders (id)
);

-- 索引优化
CREATE INDEX idx_spider_logs_spider_id ON spider_logs(spider_id);
CREATE INDEX idx_spider_logs_timestamp ON spider_logs(timestamp);
CREATE INDEX idx_spider_logs_execution_id ON spider_logs(execution_id);
```

### 3. API设计提示词

#### RESTful API设计
```python
实现标准的RESTful API：
- 使用HTTP方法表示操作类型
- 资源导向的URL设计
- 统一的请求响应格式
- 完整的HTTP状态码使用
- 支持内容协商和版本控制
- 实现API文档自动生成
```

#### 请求验证和处理
```python
创建完善的请求处理机制：
from functools import wraps
from flask import request, jsonify

def validate_json(*required_fields):
    """JSON请求验证装饰器"""
    def decorator(f):
        @wraps(f)
        def decorated_function(*args, **kwargs):
            if not request.is_json:
                return jsonify({'error': 'Content-Type must be application/json'}), 400
            
            data = request.get_json()
            if not data:
                return jsonify({'error': 'Invalid JSON data'}), 400
            
            for field in required_fields:
                if field not in data:
                    return jsonify({'error': f'Missing required field: {field}'}), 400
            
            return f(*args, **kwargs)
        return decorated_function
    return decorator

def paginate_query(default_per_page=20, max_per_page=100):
    """分页查询装饰器"""
    def decorator(f):
        @wraps(f)
        def decorated_function(*args, **kwargs):
            page = request.args.get('page', 1, type=int)
            per_page = min(
                request.args.get('per_page', default_per_page, type=int),
                max_per_page
            )
            
            kwargs['page'] = page
            kwargs['per_page'] = per_page
            
            return f(*args, **kwargs)
        return decorated_function
    return decorator
```

#### 响应格式标准化
```python
创建统一的API响应格式：
class APIResponse:
    @staticmethod
    def success(data=None, message="操作成功", code=200):
        """成功响应"""
        response = {
            'success': True,
            'code': code,
            'message': message,
            'timestamp': datetime.utcnow().isoformat(),
        }
        if data is not None:
            response['data'] = data
        return jsonify(response), code
    
    @staticmethod
    def error(message="操作失败", code=400, error_code=None, details=None):
        """错误响应"""
        response = {
            'success': False,
            'code': code,
            'message': message,
            'timestamp': datetime.utcnow().isoformat(),
        }
        if error_code:
            response['error_code'] = error_code
        if details:
            response['details'] = details
        return jsonify(response), code
    
    @staticmethod
    def paginated(data, page, per_page, total, message="获取成功"):
        """分页响应"""
        return APIResponse.success({
            'items': data,
            'pagination': {
                'page': page,
                'per_page': per_page,
                'total': total,
                'pages': (total + per_page - 1) // per_page
            }
        }, message)
```

### 4. 任务调度提示词

#### APScheduler集成
```python
实现强大的任务调度系统：
from apscheduler.schedulers.background import BackgroundScheduler
from apscheduler.triggers.cron import CronTrigger
from apscheduler.triggers.interval import IntervalTrigger

class TaskScheduler:
    def __init__(self):
        self.scheduler = BackgroundScheduler()
        self.scheduler.start()
    
    def add_cron_job(self, func, cron_expression, job_id, **kwargs):
        """添加cron定时任务"""
        try:
            trigger = CronTrigger.from_crontab(cron_expression)
            self.scheduler.add_job(
                func=func,
                trigger=trigger,
                id=job_id,
                replace_existing=True,
                **kwargs
            )
            return True
        except Exception as e:
            logger.error(f"Failed to add cron job {job_id}: {e}")
            return False
    
    def add_interval_job(self, func, seconds, job_id, **kwargs):
        """添加间隔执行任务"""
        try:
            trigger = IntervalTrigger(seconds=seconds)
            self.scheduler.add_job(
                func=func,
                trigger=trigger,
                id=job_id,
                replace_existing=True,
                **kwargs
            )
            return True
        except Exception as e:
            logger.error(f"Failed to add interval job {job_id}: {e}")
            return False
    
    def remove_job(self, job_id):
        """移除任务"""
        try:
            self.scheduler.remove_job(job_id)
            return True
        except Exception as e:
            logger.error(f"Failed to remove job {job_id}: {e}")
            return False
```

#### 任务执行监控
```python
实现任务执行状态监控：
import threading
from datetime import datetime
from enum import Enum

class TaskStatus(Enum):
    PENDING = "pending"
    RUNNING = "running"
    SUCCESS = "success"
    FAILED = "failed"
    CANCELLED = "cancelled"

class TaskMonitor:
    def __init__(self):
        self.tasks = {}
        self.lock = threading.Lock()
    
    def start_task(self, task_id, task_name):
        """开始任务监控"""
        with self.lock:
            self.tasks[task_id] = {
                'name': task_name,
                'status': TaskStatus.RUNNING,
                'start_time': datetime.utcnow(),
                'end_time': None,
                'duration': None,
                'result': None,
                'error': None
            }
    
    def finish_task(self, task_id, status, result=None, error=None):
        """完成任务监控"""
        with self.lock:
            if task_id in self.tasks:
                task = self.tasks[task_id]
                task['status'] = status
                task['end_time'] = datetime.utcnow()
                task['duration'] = (task['end_time'] - task['start_time']).total_seconds()
                task['result'] = result
                task['error'] = error
    
    def get_task_status(self, task_id):
        """获取任务状态"""
        with self.lock:
            return self.tasks.get(task_id)
```

### 5. 爬虫执行引擎提示词

#### 安全代码执行
```python
实现安全的爬虫代码执行环境：
import subprocess
import tempfile
import os
import threading
from datetime import datetime

class SpiderExecutor:
    def __init__(self, max_concurrent=5):
        self.max_concurrent = max_concurrent
        self.running_tasks = {}
        self.semaphore = threading.Semaphore(max_concurrent)
        
    def execute_spider(self, spider_id, code, execution_id):
        """执行爬虫代码"""
        self.semaphore.acquire()
        try:
            return self._run_spider_in_sandbox(spider_id, code, execution_id)
        finally:
            self.semaphore.release()
    
    def _run_spider_in_sandbox(self, spider_id, code, execution_id):
        """在沙箱环境中运行爬虫"""
        # 创建临时文件
        with tempfile.NamedTemporaryFile(mode='w', suffix='.py', delete=False) as f:
            # 注入安全代码和工具函数
            safe_code = self._prepare_safe_code(code, spider_id, execution_id)
            f.write(safe_code)
            temp_file = f.name
        
        try:
            # 创建输出目录
            output_dir = f"spider_files/spider_{spider_id}/{execution_id}"
            os.makedirs(output_dir, exist_ok=True)
            
            # 设置环境变量
            env = os.environ.copy()
            env.update({
                'SPIDER_ID': str(spider_id),
                'EXECUTION_ID': execution_id,
                'OUTPUT_DIR': output_dir,
                'PYTHONPATH': os.getcwd()
            })
            
            # 执行代码
            process = subprocess.Popen(
                [sys.executable, temp_file],
                stdout=subprocess.PIPE,
                stderr=subprocess.PIPE,
                text=True,
                cwd=output_dir,
                env=env,
                timeout=3600  # 1小时超时
            )
            
            stdout, stderr = process.communicate()
            return {
                'returncode': process.returncode,
                'stdout': stdout,
                'stderr': stderr
            }
            
        finally:
            # 清理临时文件
            try:
                os.unlink(temp_file)
            except:
                pass
```

#### 实时日志捕获
```python
实现实时日志捕获和处理：
import logging
import queue
import threading
from datetime import datetime

class LogCapture:
    def __init__(self, spider_id, execution_id):
        self.spider_id = spider_id
        self.execution_id = execution_id
        self.log_queue = queue.Queue()
        self.logger = self._setup_logger()
        self.running = False
        
    def _setup_logger(self):
        """设置日志记录器"""
        logger = logging.getLogger(f'spider_{self.spider_id}_{self.execution_id}')
        logger.setLevel(logging.DEBUG)
        
        # 创建队列处理器
        handler = QueueHandler(self.log_queue)
        formatter = logging.Formatter(
            '%(asctime)s - %(name)s - %(levelname)s - %(message)s'
        )
        handler.setFormatter(formatter)
        logger.addHandler(handler)
        
        return logger
    
    def start_capture(self):
        """开始日志捕获"""
        self.running = True
        thread = threading.Thread(target=self._process_logs)
        thread.daemon = True
        thread.start()
        
    def _process_logs(self):
        """处理日志队列"""
        db = get_db()
        while self.running:
            try:
                record = self.log_queue.get(timeout=1)
                # 保存到数据库
                db.create_log(
                    spider_id=self.spider_id,
                    level=record.levelname,
                    message=record.getMessage(),
                    source='spider_execution',
                    execution_id=self.execution_id
                )
            except queue.Empty:
                continue
            except Exception as e:
                logging.error(f"Error processing log: {e}")
```

### 6. 安全性实现提示词

#### 输入验证和过滤
```python
实现完整的输入验证系统：
import re
from functools import wraps
from flask import request, jsonify

class InputValidator:
    @staticmethod
    def validate_string(value, min_length=0, max_length=255, pattern=None):
        """字符串验证"""
        if not isinstance(value, str):
            return False, "Must be a string"
        
        if len(value) < min_length:
            return False, f"Minimum length is {min_length}"
        
        if len(value) > max_length:
            return False, f"Maximum length is {max_length}"
        
        if pattern and not re.match(pattern, value):
            return False, "Invalid format"
        
        return True, None
    
    @staticmethod
    def validate_integer(value, min_value=None, max_value=None):
        """整数验证"""
        try:
            value = int(value)
        except (ValueError, TypeError):
            return False, "Must be an integer"
        
        if min_value is not None and value < min_value:
            return False, f"Minimum value is {min_value}"
        
        if max_value is not None and value > max_value:
            return False, f"Maximum value is {max_value}"
        
        return True, None
    
    @staticmethod
    def sanitize_sql(value):
        """SQL注入防护"""
        if isinstance(value, str):
            # 移除或转义危险字符
            dangerous_chars = ["'", '"', ';', '--', '/*', '*/', 'xp_', 'sp_']
            for char in dangerous_chars:
                value = value.replace(char, '')
        return value

def validate_params(**validators):
    """参数验证装饰器"""
    def decorator(f):
        @wraps(f)
        def decorated_function(*args, **kwargs):
            errors = {}
            
            # 验证查询参数
            for param, validator in validators.items():
                value = request.args.get(param) or request.json.get(param) if request.is_json else None
                
                if value is not None:
                    is_valid, error = validator(value)
                    if not is_valid:
                        errors[param] = error
            
            if errors:
                return jsonify({'errors': errors}), 400
            
            return f(*args, **kwargs)
        return decorated_function
    return decorator
```

#### 文件上传安全
```python
实现安全的文件上传处理：
import os
import magic
from werkzeug.utils import secure_filename

class FileUploadHandler:
    ALLOWED_EXTENSIONS = {
        'txt', 'csv', 'json', 'xml', 'html', 'py', 'js', 'css',
        'jpg', 'jpeg', 'png', 'gif', 'pdf', 'log'
    }
    
    MAX_FILE_SIZE = 10 * 1024 * 1024  # 10MB
    
    @classmethod
    def validate_file(cls, file):
        """验证上传文件"""
        if not file:
            return False, "No file provided"
        
        if file.filename == '':
            return False, "No file selected"
        
        # 检查文件扩展名
        if not cls._allowed_file(file.filename):
            return False, "File type not allowed"
        
        # 检查文件大小
        file.seek(0, os.SEEK_END)
        file_size = file.tell()
        file.seek(0)
        
        if file_size > cls.MAX_FILE_SIZE:
            return False, f"File too large (max {cls.MAX_FILE_SIZE} bytes)"
        
        # 检查文件内容类型
        if not cls._validate_file_content(file):
            return False, "Invalid file content"
        
        return True, None
    
    @classmethod
    def _allowed_file(cls, filename):
        """检查文件扩展名"""
        return '.' in filename and \
               filename.rsplit('.', 1)[1].lower() in cls.ALLOWED_EXTENSIONS
    
    @classmethod
    def _validate_file_content(cls, file):
        """验证文件内容类型"""
        try:
            # 读取文件头部分析MIME类型
            header = file.read(1024)
            file.seek(0)
            
            mime_type = magic.from_buffer(header, mime=True)
            
            # 定义允许的MIME类型
            allowed_mimes = {
                'text/plain', 'text/csv', 'application/json',
                'text/xml', 'text/html', 'text/x-python',
                'text/javascript', 'text/css',
                'image/jpeg', 'image/png', 'image/gif',
                'application/pdf'
            }
            
            return mime_type in allowed_mimes
        except:
            return False
    
    @classmethod
    def save_file(cls, file, upload_folder):
        """安全保存文件"""
        filename = secure_filename(file.filename)
        
        # 生成唯一文件名
        name, ext = os.path.splitext(filename)
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        unique_filename = f"{name}_{timestamp}{ext}"
        
        filepath = os.path.join(upload_folder, unique_filename)
        
        # 确保目录存在
        os.makedirs(upload_folder, exist_ok=True)
        
        # 保存文件
        file.save(filepath)
        
        return unique_filename, filepath
```

### 7. 性能优化提示词

#### 数据库查询优化
```python
实现高效的数据库查询：
class DatabaseOptimizer:
    @staticmethod
    def build_query_with_filters(base_query, conditions, params):
        """动态构建查询条件"""
        where_clause = " AND ".join(conditions) if conditions else "1=1"
        return f"{base_query} WHERE {where_clause}", params
    
    @staticmethod
    def paginate_query(query, page, per_page):
        """分页查询优化"""
        offset = (page - 1) * per_page
        paginated_query = f"{query} LIMIT {per_page} OFFSET {offset}"
        
        # 计算总数的优化查询
        count_query = f"SELECT COUNT(*) FROM ({query}) as count_table"
        
        return paginated_query, count_query
    
    @staticmethod
    def optimize_joins(table1, table2, join_key):
        """优化表连接"""
        return f"""
        SELECT t1.*, t2.* 
        FROM {table1} t1 
        INNER JOIN {table2} t2 ON t1.{join_key} = t2.id
        """
```

#### 缓存策略实现
```python
实现多层缓存策略：
import redis
import json
from functools import wraps
from datetime import timedelta

class CacheManager:
    def __init__(self, redis_url=None):
        self.redis_client = redis.from_url(redis_url) if redis_url else None
        self.memory_cache = {}
    
    def cached(self, key_prefix, expiration=3600):
        """缓存装饰器"""
        def decorator(f):
            @wraps(f)
            def decorated_function(*args, **kwargs):
                # 生成缓存键
                cache_key = f"{key_prefix}:{hash(str(args) + str(kwargs))}"
                
                # 尝试从缓存获取
                cached_result = self.get(cache_key)
                if cached_result is not None:
                    return cached_result
                
                # 执行函数并缓存结果
                result = f(*args, **kwargs)
                self.set(cache_key, result, expiration)
                
                return result
            return decorated_function
        return decorator
    
    def get(self, key):
        """获取缓存"""
        # 首先尝试Redis
        if self.redis_client:
            try:
                data = self.redis_client.get(key)
                if data:
                    return json.loads(data)
            except:
                pass
        
        # 回退到内存缓存
        return self.memory_cache.get(key)
    
    def set(self, key, value, expiration=3600):
        """设置缓存"""
        # 设置Redis缓存
        if self.redis_client:
            try:
                self.redis_client.setex(
                    key, 
                    expiration, 
                    json.dumps(value, default=str)
                )
            except:
                pass
        
        # 设置内存缓存
        self.memory_cache[key] = value
    
    def delete(self, key):
        """删除缓存"""
        if self.redis_client:
            try:
                self.redis_client.delete(key)
            except:
                pass
        
        self.memory_cache.pop(key, None)
```

### 8. 监控和日志提示词

#### 性能监控实现
```python
实现全面的性能监控：
import time
import psutil
from functools import wraps

class PerformanceMonitor:
    def __init__(self):
        self.metrics = {}
    
    def monitor_execution_time(self, operation_name):
        """监控执行时间装饰器"""
        def decorator(f):
            @wraps(f)
            def decorated_function(*args, **kwargs):
                start_time = time.time()
                
                try:
                    result = f(*args, **kwargs)
                    status = 'success'
                except Exception as e:
                    result = None
                    status = 'error'
                    raise
                finally:
                    execution_time = time.time() - start_time
                    self._record_metric(operation_name, execution_time, status)
                
                return result
            return decorated_function
        return decorator
    
    def _record_metric(self, operation, execution_time, status):
        """记录性能指标"""
        if operation not in self.metrics:
            self.metrics[operation] = {
                'total_calls': 0,
                'success_calls': 0,
                'error_calls': 0,
                'total_time': 0,
                'avg_time': 0,
                'max_time': 0,
                'min_time': float('inf')
            }
        
        metric = self.metrics[operation]
        metric['total_calls'] += 1
        metric['total_time'] += execution_time
        metric['avg_time'] = metric['total_time'] / metric['total_calls']
        metric['max_time'] = max(metric['max_time'], execution_time)
        metric['min_time'] = min(metric['min_time'], execution_time)
        
        if status == 'success':
            metric['success_calls'] += 1
        else:
            metric['error_calls'] += 1
    
    def get_system_metrics(self):
        """获取系统性能指标"""
        return {
            'cpu_percent': psutil.cpu_percent(),
            'memory_percent': psutil.virtual_memory().percent,
            'disk_usage': psutil.disk_usage('/').percent,
            'network_io': psutil.net_io_counters()._asdict(),
            'process_count': len(psutil.pids())
        }
```

## 📋 实现检查清单

### Flask应用架构
- [ ] 使用应用工厂模式
- [ ] Blueprint模块化设计
- [ ] 中间件和错误处理
- [ ] 配置管理和环境变量
- [ ] 健康检查接口

### API设计规范
- [ ] RESTful设计原则
- [ ] 统一响应格式
- [ ] 输入验证和过滤
- [ ] 分页排序筛选
- [ ] API文档和测试

### 数据库优化
- [ ] 合理的表结构设计
- [ ] 索引策略优化
- [ ] 查询性能优化
- [ ] 事务和连接管理
- [ ] 备份恢复机制

### 任务调度系统
- [ ] APScheduler集成
- [ ] 任务状态监控
- [ ] 失败重试机制
- [ ] 并发控制
- [ ] 性能监控

### 安全性保障
- [ ] 输入验证和过滤
- [ ] SQL注入防护
- [ ] 文件上传安全
- [ ] 认证授权
- [ ] 访问控制

### 性能优化
- [ ] 数据库查询优化
- [ ] 缓存策略实现
- [ ] 异步处理
- [ ] 资源监控
- [ ] 压力测试

### 监控和日志
- [ ] 结构化日志
- [ ] 性能监控
- [ ] 错误追踪
- [ ] 系统监控
- [ ] 告警机制

---

*这些关键词和实现指南将帮助您构建高质量、高性能的后端服务，确保系统的稳定性和可扩展性。* 