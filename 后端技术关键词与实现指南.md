# åç«¯æŠ€æœ¯å…³é”®è¯ä¸å®ç°æŒ‡å—

## ğŸ¯ æ ¸å¿ƒæŠ€æœ¯å…³é”®è¯

### Flaskæ¡†æ¶å…³é”®è¯
```
è½»é‡çº§ã€çµæ´»æ€§ã€å¯æ‰©å±•ã€å¾®æœåŠ¡ã€Blueprintã€ä¸­é—´ä»¶ã€è£…é¥°å™¨ã€ä¸Šä¸‹æ–‡
```

### æ•°æ®åº“è®¾è®¡å…³é”®è¯
```
å…³ç³»å‹ã€ACIDã€äº‹åŠ¡ã€ç´¢å¼•ã€æŸ¥è¯¢ä¼˜åŒ–ã€è¿æ¥æ± ã€ORMã€è¿ç§»ã€å¤‡ä»½æ¢å¤
```

### APIå¼€å‘å…³é”®è¯
```
RESTfulã€HTTPåè®®ã€çŠ¶æ€ç ã€JSONã€åˆ†é¡µã€ç­›é€‰ã€æ’åºã€ç‰ˆæœ¬æ§åˆ¶ã€æ–‡æ¡£åŒ–
```

### ä»»åŠ¡è°ƒåº¦å…³é”®è¯
```
å¼‚æ­¥æ‰§è¡Œã€å®šæ—¶ä»»åŠ¡ã€cronè¡¨è¾¾å¼ã€å¹¶å‘æ§åˆ¶ã€å¤±è´¥é‡è¯•ã€çŠ¶æ€ç®¡ç†ã€ç›‘æ§å‘Šè­¦
```

### å®‰å…¨æ€§å…³é”®è¯
```
è¾“å…¥éªŒè¯ã€SQLæ³¨å…¥ã€XSSé˜²æŠ¤ã€CSRFä¿æŠ¤ã€è®¤è¯æˆæƒã€åŠ å¯†å­˜å‚¨ã€è®¿é—®æ§åˆ¶
```

### æ€§èƒ½ä¼˜åŒ–å…³é”®è¯
```
ç¼“å­˜ç­–ç•¥ã€è¿æ¥æ± ã€æŸ¥è¯¢ä¼˜åŒ–ã€å¼‚æ­¥å¤„ç†ã€è´Ÿè½½å‡è¡¡ã€èµ„æºç›‘æ§ã€æ€§èƒ½åˆ†æ
```

## ğŸ—ï¸ è¯¦ç»†å®ç°æç¤ºè¯

### 1. Flaskåº”ç”¨æ¶æ„æç¤ºè¯

#### åº”ç”¨å·¥å‚æ¨¡å¼
```python
åˆ›å»ºä¸€ä¸ªæ ‡å‡†çš„Flaskåº”ç”¨å·¥å‚ï¼š
- ä½¿ç”¨create_appå‡½æ•°åˆå§‹åŒ–åº”ç”¨
- æ”¯æŒä¸åŒç¯å¢ƒçš„é…ç½®ç®¡ç†
- æ³¨å†Œè“å›¾å’Œä¸­é—´ä»¶
- é…ç½®é”™è¯¯å¤„ç†å™¨å’Œæ—¥å¿—ç³»ç»Ÿ
- å®ç°å¥åº·æ£€æŸ¥å’Œç›‘æ§æ¥å£
- æ”¯æŒæ’ä»¶å’Œæ‰©å±•çš„åŠ¨æ€åŠ è½½
```

#### Blueprintæ¨¡å—åŒ–è®¾è®¡
```python
è®¾è®¡æ¨¡å—åŒ–çš„Blueprintæ¶æ„ï¼š
- æŒ‰åŠŸèƒ½åŸŸåˆ’åˆ†Blueprintï¼ˆspidersã€filesã€logsç­‰ï¼‰
- æ¯ä¸ªBlueprintç‹¬ç«‹çš„è·¯ç”±å’Œé”™è¯¯å¤„ç†
- ç»Ÿä¸€çš„è¯·æ±‚å“åº”æ ¼å¼
- ä¸­é—´ä»¶å¤„ç†è®¤è¯ã€æ—¥å¿—ã€è·¨åŸŸç­‰
- æ”¯æŒBlueprintçš„åŠ¨æ€æ³¨å†Œå’Œå¸è½½
- å®ç°Blueprintçº§åˆ«çš„æƒé™æ§åˆ¶
```

#### ä¸­é—´ä»¶å’Œè£…é¥°å™¨
```python
å®ç°åŠŸèƒ½ä¸°å¯Œçš„ä¸­é—´ä»¶ç³»ç»Ÿï¼š
- è¯·æ±‚æ—¥å¿—è®°å½•å’Œæ€§èƒ½ç›‘æ§
- ç”¨æˆ·è®¤è¯å’Œæƒé™éªŒè¯
- è¯·æ±‚å‚æ•°éªŒè¯å’Œæ ¼å¼åŒ–
- å“åº”æ•°æ®å‹ç¼©å’Œç¼“å­˜
- å¼‚å¸¸æ•è·å’Œé”™è¯¯å¤„ç†
- è·¨åŸŸèµ„æºå…±äº«(CORS)å¤„ç†
```

### 2. æ•°æ®åº“è®¾è®¡æç¤ºè¯

#### æ•°æ®åº“è¿æ¥ç®¡ç†
```python
å®ç°é«˜æ•ˆçš„æ•°æ®åº“è¿æ¥ç®¡ç†ï¼š
- ä½¿ç”¨ä¸Šä¸‹æ–‡ç®¡ç†å™¨è‡ªåŠ¨ç®¡ç†è¿æ¥
- å®ç°è¿æ¥æ± å‡å°‘è¿æ¥å¼€é”€
- æ”¯æŒäº‹åŠ¡æ“ä½œå’Œå›æ»šæœºåˆ¶
- å®ç°è¯»å†™åˆ†ç¦»å’Œè´Ÿè½½å‡è¡¡
- æä¾›è¿æ¥å¥åº·æ£€æŸ¥å’Œè‡ªåŠ¨é‡è¿
- ç›‘æ§è¿æ¥ä½¿ç”¨æƒ…å†µå’Œæ€§èƒ½
```

#### æ•°æ®è®¿é—®å±‚è®¾è®¡
```python
æ„å»ºæ ‡å‡†çš„æ•°æ®è®¿é—®å±‚ï¼š
- å®ç°DAOæ¨¡å¼å°è£…æ•°æ®æ“ä½œ
- æä¾›é€šç”¨çš„CRUDæ“ä½œæ¥å£
- æ”¯æŒå¤æ‚æŸ¥è¯¢å’Œèšåˆæ“ä½œ
- å®ç°æŸ¥è¯¢ç¼“å­˜å’Œç»“æœä¼˜åŒ–
- æä¾›æ‰¹é‡æ“ä½œå’Œäº‹åŠ¡æ”¯æŒ
- å®ç°æ•°æ®éªŒè¯å’Œçº¦æŸæ£€æŸ¥
```

#### æ•°æ®åº“è¡¨ç»“æ„è®¾è®¡
```sql
è®¾è®¡åˆç†çš„æ•°æ®åº“è¡¨ç»“æ„ï¼š
-- çˆ¬è™«è¡¨
CREATE TABLE spiders (
    id INTEGER PRIMARY KEY AUTOINCREMENT,
    name TEXT NOT NULL UNIQUE,
    description TEXT,
    code TEXT NOT NULL,
    status TEXT DEFAULT 'inactive',
    config TEXT DEFAULT '{}',
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    last_run_at TIMESTAMP,
    run_count INTEGER DEFAULT 0,
    success_count INTEGER DEFAULT 0,
    error_count INTEGER DEFAULT 0
);

-- æ—¥å¿—è¡¨
CREATE TABLE spider_logs (
    id INTEGER PRIMARY KEY AUTOINCREMENT,
    spider_id INTEGER NOT NULL,
    level TEXT NOT NULL,
    message TEXT NOT NULL,
    timestamp TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    source TEXT,
    execution_id TEXT,
    FOREIGN KEY (spider_id) REFERENCES spiders (id)
);

-- ç´¢å¼•ä¼˜åŒ–
CREATE INDEX idx_spider_logs_spider_id ON spider_logs(spider_id);
CREATE INDEX idx_spider_logs_timestamp ON spider_logs(timestamp);
CREATE INDEX idx_spider_logs_execution_id ON spider_logs(execution_id);
```

### 3. APIè®¾è®¡æç¤ºè¯

#### RESTful APIè®¾è®¡
```python
å®ç°æ ‡å‡†çš„RESTful APIï¼š
- ä½¿ç”¨HTTPæ–¹æ³•è¡¨ç¤ºæ“ä½œç±»å‹
- èµ„æºå¯¼å‘çš„URLè®¾è®¡
- ç»Ÿä¸€çš„è¯·æ±‚å“åº”æ ¼å¼
- å®Œæ•´çš„HTTPçŠ¶æ€ç ä½¿ç”¨
- æ”¯æŒå†…å®¹åå•†å’Œç‰ˆæœ¬æ§åˆ¶
- å®ç°APIæ–‡æ¡£è‡ªåŠ¨ç”Ÿæˆ
```

#### è¯·æ±‚éªŒè¯å’Œå¤„ç†
```python
åˆ›å»ºå®Œå–„çš„è¯·æ±‚å¤„ç†æœºåˆ¶ï¼š
from functools import wraps
from flask import request, jsonify

def validate_json(*required_fields):
    """JSONè¯·æ±‚éªŒè¯è£…é¥°å™¨"""
    def decorator(f):
        @wraps(f)
        def decorated_function(*args, **kwargs):
            if not request.is_json:
                return jsonify({'error': 'Content-Type must be application/json'}), 400
            
            data = request.get_json()
            if not data:
                return jsonify({'error': 'Invalid JSON data'}), 400
            
            for field in required_fields:
                if field not in data:
                    return jsonify({'error': f'Missing required field: {field}'}), 400
            
            return f(*args, **kwargs)
        return decorated_function
    return decorator

def paginate_query(default_per_page=20, max_per_page=100):
    """åˆ†é¡µæŸ¥è¯¢è£…é¥°å™¨"""
    def decorator(f):
        @wraps(f)
        def decorated_function(*args, **kwargs):
            page = request.args.get('page', 1, type=int)
            per_page = min(
                request.args.get('per_page', default_per_page, type=int),
                max_per_page
            )
            
            kwargs['page'] = page
            kwargs['per_page'] = per_page
            
            return f(*args, **kwargs)
        return decorated_function
    return decorator
```

#### å“åº”æ ¼å¼æ ‡å‡†åŒ–
```python
åˆ›å»ºç»Ÿä¸€çš„APIå“åº”æ ¼å¼ï¼š
class APIResponse:
    @staticmethod
    def success(data=None, message="æ“ä½œæˆåŠŸ", code=200):
        """æˆåŠŸå“åº”"""
        response = {
            'success': True,
            'code': code,
            'message': message,
            'timestamp': datetime.utcnow().isoformat(),
        }
        if data is not None:
            response['data'] = data
        return jsonify(response), code
    
    @staticmethod
    def error(message="æ“ä½œå¤±è´¥", code=400, error_code=None, details=None):
        """é”™è¯¯å“åº”"""
        response = {
            'success': False,
            'code': code,
            'message': message,
            'timestamp': datetime.utcnow().isoformat(),
        }
        if error_code:
            response['error_code'] = error_code
        if details:
            response['details'] = details
        return jsonify(response), code
    
    @staticmethod
    def paginated(data, page, per_page, total, message="è·å–æˆåŠŸ"):
        """åˆ†é¡µå“åº”"""
        return APIResponse.success({
            'items': data,
            'pagination': {
                'page': page,
                'per_page': per_page,
                'total': total,
                'pages': (total + per_page - 1) // per_page
            }
        }, message)
```

### 4. ä»»åŠ¡è°ƒåº¦æç¤ºè¯

#### APScheduleré›†æˆ
```python
å®ç°å¼ºå¤§çš„ä»»åŠ¡è°ƒåº¦ç³»ç»Ÿï¼š
from apscheduler.schedulers.background import BackgroundScheduler
from apscheduler.triggers.cron import CronTrigger
from apscheduler.triggers.interval import IntervalTrigger

class TaskScheduler:
    def __init__(self):
        self.scheduler = BackgroundScheduler()
        self.scheduler.start()
    
    def add_cron_job(self, func, cron_expression, job_id, **kwargs):
        """æ·»åŠ cronå®šæ—¶ä»»åŠ¡"""
        try:
            trigger = CronTrigger.from_crontab(cron_expression)
            self.scheduler.add_job(
                func=func,
                trigger=trigger,
                id=job_id,
                replace_existing=True,
                **kwargs
            )
            return True
        except Exception as e:
            logger.error(f"Failed to add cron job {job_id}: {e}")
            return False
    
    def add_interval_job(self, func, seconds, job_id, **kwargs):
        """æ·»åŠ é—´éš”æ‰§è¡Œä»»åŠ¡"""
        try:
            trigger = IntervalTrigger(seconds=seconds)
            self.scheduler.add_job(
                func=func,
                trigger=trigger,
                id=job_id,
                replace_existing=True,
                **kwargs
            )
            return True
        except Exception as e:
            logger.error(f"Failed to add interval job {job_id}: {e}")
            return False
    
    def remove_job(self, job_id):
        """ç§»é™¤ä»»åŠ¡"""
        try:
            self.scheduler.remove_job(job_id)
            return True
        except Exception as e:
            logger.error(f"Failed to remove job {job_id}: {e}")
            return False
```

#### ä»»åŠ¡æ‰§è¡Œç›‘æ§
```python
å®ç°ä»»åŠ¡æ‰§è¡ŒçŠ¶æ€ç›‘æ§ï¼š
import threading
from datetime import datetime
from enum import Enum

class TaskStatus(Enum):
    PENDING = "pending"
    RUNNING = "running"
    SUCCESS = "success"
    FAILED = "failed"
    CANCELLED = "cancelled"

class TaskMonitor:
    def __init__(self):
        self.tasks = {}
        self.lock = threading.Lock()
    
    def start_task(self, task_id, task_name):
        """å¼€å§‹ä»»åŠ¡ç›‘æ§"""
        with self.lock:
            self.tasks[task_id] = {
                'name': task_name,
                'status': TaskStatus.RUNNING,
                'start_time': datetime.utcnow(),
                'end_time': None,
                'duration': None,
                'result': None,
                'error': None
            }
    
    def finish_task(self, task_id, status, result=None, error=None):
        """å®Œæˆä»»åŠ¡ç›‘æ§"""
        with self.lock:
            if task_id in self.tasks:
                task = self.tasks[task_id]
                task['status'] = status
                task['end_time'] = datetime.utcnow()
                task['duration'] = (task['end_time'] - task['start_time']).total_seconds()
                task['result'] = result
                task['error'] = error
    
    def get_task_status(self, task_id):
        """è·å–ä»»åŠ¡çŠ¶æ€"""
        with self.lock:
            return self.tasks.get(task_id)
```

### 5. çˆ¬è™«æ‰§è¡Œå¼•æ“æç¤ºè¯

#### å®‰å…¨ä»£ç æ‰§è¡Œ
```python
å®ç°å®‰å…¨çš„çˆ¬è™«ä»£ç æ‰§è¡Œç¯å¢ƒï¼š
import subprocess
import tempfile
import os
import threading
from datetime import datetime

class SpiderExecutor:
    def __init__(self, max_concurrent=5):
        self.max_concurrent = max_concurrent
        self.running_tasks = {}
        self.semaphore = threading.Semaphore(max_concurrent)
        
    def execute_spider(self, spider_id, code, execution_id):
        """æ‰§è¡Œçˆ¬è™«ä»£ç """
        self.semaphore.acquire()
        try:
            return self._run_spider_in_sandbox(spider_id, code, execution_id)
        finally:
            self.semaphore.release()
    
    def _run_spider_in_sandbox(self, spider_id, code, execution_id):
        """åœ¨æ²™ç®±ç¯å¢ƒä¸­è¿è¡Œçˆ¬è™«"""
        # åˆ›å»ºä¸´æ—¶æ–‡ä»¶
        with tempfile.NamedTemporaryFile(mode='w', suffix='.py', delete=False) as f:
            # æ³¨å…¥å®‰å…¨ä»£ç å’Œå·¥å…·å‡½æ•°
            safe_code = self._prepare_safe_code(code, spider_id, execution_id)
            f.write(safe_code)
            temp_file = f.name
        
        try:
            # åˆ›å»ºè¾“å‡ºç›®å½•
            output_dir = f"spider_files/spider_{spider_id}/{execution_id}"
            os.makedirs(output_dir, exist_ok=True)
            
            # è®¾ç½®ç¯å¢ƒå˜é‡
            env = os.environ.copy()
            env.update({
                'SPIDER_ID': str(spider_id),
                'EXECUTION_ID': execution_id,
                'OUTPUT_DIR': output_dir,
                'PYTHONPATH': os.getcwd()
            })
            
            # æ‰§è¡Œä»£ç 
            process = subprocess.Popen(
                [sys.executable, temp_file],
                stdout=subprocess.PIPE,
                stderr=subprocess.PIPE,
                text=True,
                cwd=output_dir,
                env=env,
                timeout=3600  # 1å°æ—¶è¶…æ—¶
            )
            
            stdout, stderr = process.communicate()
            return {
                'returncode': process.returncode,
                'stdout': stdout,
                'stderr': stderr
            }
            
        finally:
            # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
            try:
                os.unlink(temp_file)
            except:
                pass
```

#### å®æ—¶æ—¥å¿—æ•è·
```python
å®ç°å®æ—¶æ—¥å¿—æ•è·å’Œå¤„ç†ï¼š
import logging
import queue
import threading
from datetime import datetime

class LogCapture:
    def __init__(self, spider_id, execution_id):
        self.spider_id = spider_id
        self.execution_id = execution_id
        self.log_queue = queue.Queue()
        self.logger = self._setup_logger()
        self.running = False
        
    def _setup_logger(self):
        """è®¾ç½®æ—¥å¿—è®°å½•å™¨"""
        logger = logging.getLogger(f'spider_{self.spider_id}_{self.execution_id}')
        logger.setLevel(logging.DEBUG)
        
        # åˆ›å»ºé˜Ÿåˆ—å¤„ç†å™¨
        handler = QueueHandler(self.log_queue)
        formatter = logging.Formatter(
            '%(asctime)s - %(name)s - %(levelname)s - %(message)s'
        )
        handler.setFormatter(formatter)
        logger.addHandler(handler)
        
        return logger
    
    def start_capture(self):
        """å¼€å§‹æ—¥å¿—æ•è·"""
        self.running = True
        thread = threading.Thread(target=self._process_logs)
        thread.daemon = True
        thread.start()
        
    def _process_logs(self):
        """å¤„ç†æ—¥å¿—é˜Ÿåˆ—"""
        db = get_db()
        while self.running:
            try:
                record = self.log_queue.get(timeout=1)
                # ä¿å­˜åˆ°æ•°æ®åº“
                db.create_log(
                    spider_id=self.spider_id,
                    level=record.levelname,
                    message=record.getMessage(),
                    source='spider_execution',
                    execution_id=self.execution_id
                )
            except queue.Empty:
                continue
            except Exception as e:
                logging.error(f"Error processing log: {e}")
```

### 6. å®‰å…¨æ€§å®ç°æç¤ºè¯

#### è¾“å…¥éªŒè¯å’Œè¿‡æ»¤
```python
å®ç°å®Œæ•´çš„è¾“å…¥éªŒè¯ç³»ç»Ÿï¼š
import re
from functools import wraps
from flask import request, jsonify

class InputValidator:
    @staticmethod
    def validate_string(value, min_length=0, max_length=255, pattern=None):
        """å­—ç¬¦ä¸²éªŒè¯"""
        if not isinstance(value, str):
            return False, "Must be a string"
        
        if len(value) < min_length:
            return False, f"Minimum length is {min_length}"
        
        if len(value) > max_length:
            return False, f"Maximum length is {max_length}"
        
        if pattern and not re.match(pattern, value):
            return False, "Invalid format"
        
        return True, None
    
    @staticmethod
    def validate_integer(value, min_value=None, max_value=None):
        """æ•´æ•°éªŒè¯"""
        try:
            value = int(value)
        except (ValueError, TypeError):
            return False, "Must be an integer"
        
        if min_value is not None and value < min_value:
            return False, f"Minimum value is {min_value}"
        
        if max_value is not None and value > max_value:
            return False, f"Maximum value is {max_value}"
        
        return True, None
    
    @staticmethod
    def sanitize_sql(value):
        """SQLæ³¨å…¥é˜²æŠ¤"""
        if isinstance(value, str):
            # ç§»é™¤æˆ–è½¬ä¹‰å±é™©å­—ç¬¦
            dangerous_chars = ["'", '"', ';', '--', '/*', '*/', 'xp_', 'sp_']
            for char in dangerous_chars:
                value = value.replace(char, '')
        return value

def validate_params(**validators):
    """å‚æ•°éªŒè¯è£…é¥°å™¨"""
    def decorator(f):
        @wraps(f)
        def decorated_function(*args, **kwargs):
            errors = {}
            
            # éªŒè¯æŸ¥è¯¢å‚æ•°
            for param, validator in validators.items():
                value = request.args.get(param) or request.json.get(param) if request.is_json else None
                
                if value is not None:
                    is_valid, error = validator(value)
                    if not is_valid:
                        errors[param] = error
            
            if errors:
                return jsonify({'errors': errors}), 400
            
            return f(*args, **kwargs)
        return decorated_function
    return decorator
```

#### æ–‡ä»¶ä¸Šä¼ å®‰å…¨
```python
å®ç°å®‰å…¨çš„æ–‡ä»¶ä¸Šä¼ å¤„ç†ï¼š
import os
import magic
from werkzeug.utils import secure_filename

class FileUploadHandler:
    ALLOWED_EXTENSIONS = {
        'txt', 'csv', 'json', 'xml', 'html', 'py', 'js', 'css',
        'jpg', 'jpeg', 'png', 'gif', 'pdf', 'log'
    }
    
    MAX_FILE_SIZE = 10 * 1024 * 1024  # 10MB
    
    @classmethod
    def validate_file(cls, file):
        """éªŒè¯ä¸Šä¼ æ–‡ä»¶"""
        if not file:
            return False, "No file provided"
        
        if file.filename == '':
            return False, "No file selected"
        
        # æ£€æŸ¥æ–‡ä»¶æ‰©å±•å
        if not cls._allowed_file(file.filename):
            return False, "File type not allowed"
        
        # æ£€æŸ¥æ–‡ä»¶å¤§å°
        file.seek(0, os.SEEK_END)
        file_size = file.tell()
        file.seek(0)
        
        if file_size > cls.MAX_FILE_SIZE:
            return False, f"File too large (max {cls.MAX_FILE_SIZE} bytes)"
        
        # æ£€æŸ¥æ–‡ä»¶å†…å®¹ç±»å‹
        if not cls._validate_file_content(file):
            return False, "Invalid file content"
        
        return True, None
    
    @classmethod
    def _allowed_file(cls, filename):
        """æ£€æŸ¥æ–‡ä»¶æ‰©å±•å"""
        return '.' in filename and \
               filename.rsplit('.', 1)[1].lower() in cls.ALLOWED_EXTENSIONS
    
    @classmethod
    def _validate_file_content(cls, file):
        """éªŒè¯æ–‡ä»¶å†…å®¹ç±»å‹"""
        try:
            # è¯»å–æ–‡ä»¶å¤´éƒ¨åˆ†æMIMEç±»å‹
            header = file.read(1024)
            file.seek(0)
            
            mime_type = magic.from_buffer(header, mime=True)
            
            # å®šä¹‰å…è®¸çš„MIMEç±»å‹
            allowed_mimes = {
                'text/plain', 'text/csv', 'application/json',
                'text/xml', 'text/html', 'text/x-python',
                'text/javascript', 'text/css',
                'image/jpeg', 'image/png', 'image/gif',
                'application/pdf'
            }
            
            return mime_type in allowed_mimes
        except:
            return False
    
    @classmethod
    def save_file(cls, file, upload_folder):
        """å®‰å…¨ä¿å­˜æ–‡ä»¶"""
        filename = secure_filename(file.filename)
        
        # ç”Ÿæˆå”¯ä¸€æ–‡ä»¶å
        name, ext = os.path.splitext(filename)
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        unique_filename = f"{name}_{timestamp}{ext}"
        
        filepath = os.path.join(upload_folder, unique_filename)
        
        # ç¡®ä¿ç›®å½•å­˜åœ¨
        os.makedirs(upload_folder, exist_ok=True)
        
        # ä¿å­˜æ–‡ä»¶
        file.save(filepath)
        
        return unique_filename, filepath
```

### 7. æ€§èƒ½ä¼˜åŒ–æç¤ºè¯

#### æ•°æ®åº“æŸ¥è¯¢ä¼˜åŒ–
```python
å®ç°é«˜æ•ˆçš„æ•°æ®åº“æŸ¥è¯¢ï¼š
class DatabaseOptimizer:
    @staticmethod
    def build_query_with_filters(base_query, conditions, params):
        """åŠ¨æ€æ„å»ºæŸ¥è¯¢æ¡ä»¶"""
        where_clause = " AND ".join(conditions) if conditions else "1=1"
        return f"{base_query} WHERE {where_clause}", params
    
    @staticmethod
    def paginate_query(query, page, per_page):
        """åˆ†é¡µæŸ¥è¯¢ä¼˜åŒ–"""
        offset = (page - 1) * per_page
        paginated_query = f"{query} LIMIT {per_page} OFFSET {offset}"
        
        # è®¡ç®—æ€»æ•°çš„ä¼˜åŒ–æŸ¥è¯¢
        count_query = f"SELECT COUNT(*) FROM ({query}) as count_table"
        
        return paginated_query, count_query
    
    @staticmethod
    def optimize_joins(table1, table2, join_key):
        """ä¼˜åŒ–è¡¨è¿æ¥"""
        return f"""
        SELECT t1.*, t2.* 
        FROM {table1} t1 
        INNER JOIN {table2} t2 ON t1.{join_key} = t2.id
        """
```

#### ç¼“å­˜ç­–ç•¥å®ç°
```python
å®ç°å¤šå±‚ç¼“å­˜ç­–ç•¥ï¼š
import redis
import json
from functools import wraps
from datetime import timedelta

class CacheManager:
    def __init__(self, redis_url=None):
        self.redis_client = redis.from_url(redis_url) if redis_url else None
        self.memory_cache = {}
    
    def cached(self, key_prefix, expiration=3600):
        """ç¼“å­˜è£…é¥°å™¨"""
        def decorator(f):
            @wraps(f)
            def decorated_function(*args, **kwargs):
                # ç”Ÿæˆç¼“å­˜é”®
                cache_key = f"{key_prefix}:{hash(str(args) + str(kwargs))}"
                
                # å°è¯•ä»ç¼“å­˜è·å–
                cached_result = self.get(cache_key)
                if cached_result is not None:
                    return cached_result
                
                # æ‰§è¡Œå‡½æ•°å¹¶ç¼“å­˜ç»“æœ
                result = f(*args, **kwargs)
                self.set(cache_key, result, expiration)
                
                return result
            return decorated_function
        return decorator
    
    def get(self, key):
        """è·å–ç¼“å­˜"""
        # é¦–å…ˆå°è¯•Redis
        if self.redis_client:
            try:
                data = self.redis_client.get(key)
                if data:
                    return json.loads(data)
            except:
                pass
        
        # å›é€€åˆ°å†…å­˜ç¼“å­˜
        return self.memory_cache.get(key)
    
    def set(self, key, value, expiration=3600):
        """è®¾ç½®ç¼“å­˜"""
        # è®¾ç½®Redisç¼“å­˜
        if self.redis_client:
            try:
                self.redis_client.setex(
                    key, 
                    expiration, 
                    json.dumps(value, default=str)
                )
            except:
                pass
        
        # è®¾ç½®å†…å­˜ç¼“å­˜
        self.memory_cache[key] = value
    
    def delete(self, key):
        """åˆ é™¤ç¼“å­˜"""
        if self.redis_client:
            try:
                self.redis_client.delete(key)
            except:
                pass
        
        self.memory_cache.pop(key, None)
```

### 8. ç›‘æ§å’Œæ—¥å¿—æç¤ºè¯

#### æ€§èƒ½ç›‘æ§å®ç°
```python
å®ç°å…¨é¢çš„æ€§èƒ½ç›‘æ§ï¼š
import time
import psutil
from functools import wraps

class PerformanceMonitor:
    def __init__(self):
        self.metrics = {}
    
    def monitor_execution_time(self, operation_name):
        """ç›‘æ§æ‰§è¡Œæ—¶é—´è£…é¥°å™¨"""
        def decorator(f):
            @wraps(f)
            def decorated_function(*args, **kwargs):
                start_time = time.time()
                
                try:
                    result = f(*args, **kwargs)
                    status = 'success'
                except Exception as e:
                    result = None
                    status = 'error'
                    raise
                finally:
                    execution_time = time.time() - start_time
                    self._record_metric(operation_name, execution_time, status)
                
                return result
            return decorated_function
        return decorator
    
    def _record_metric(self, operation, execution_time, status):
        """è®°å½•æ€§èƒ½æŒ‡æ ‡"""
        if operation not in self.metrics:
            self.metrics[operation] = {
                'total_calls': 0,
                'success_calls': 0,
                'error_calls': 0,
                'total_time': 0,
                'avg_time': 0,
                'max_time': 0,
                'min_time': float('inf')
            }
        
        metric = self.metrics[operation]
        metric['total_calls'] += 1
        metric['total_time'] += execution_time
        metric['avg_time'] = metric['total_time'] / metric['total_calls']
        metric['max_time'] = max(metric['max_time'], execution_time)
        metric['min_time'] = min(metric['min_time'], execution_time)
        
        if status == 'success':
            metric['success_calls'] += 1
        else:
            metric['error_calls'] += 1
    
    def get_system_metrics(self):
        """è·å–ç³»ç»Ÿæ€§èƒ½æŒ‡æ ‡"""
        return {
            'cpu_percent': psutil.cpu_percent(),
            'memory_percent': psutil.virtual_memory().percent,
            'disk_usage': psutil.disk_usage('/').percent,
            'network_io': psutil.net_io_counters()._asdict(),
            'process_count': len(psutil.pids())
        }
```

## ğŸ“‹ å®ç°æ£€æŸ¥æ¸…å•

### Flaskåº”ç”¨æ¶æ„
- [ ] ä½¿ç”¨åº”ç”¨å·¥å‚æ¨¡å¼
- [ ] Blueprintæ¨¡å—åŒ–è®¾è®¡
- [ ] ä¸­é—´ä»¶å’Œé”™è¯¯å¤„ç†
- [ ] é…ç½®ç®¡ç†å’Œç¯å¢ƒå˜é‡
- [ ] å¥åº·æ£€æŸ¥æ¥å£

### APIè®¾è®¡è§„èŒƒ
- [ ] RESTfulè®¾è®¡åŸåˆ™
- [ ] ç»Ÿä¸€å“åº”æ ¼å¼
- [ ] è¾“å…¥éªŒè¯å’Œè¿‡æ»¤
- [ ] åˆ†é¡µæ’åºç­›é€‰
- [ ] APIæ–‡æ¡£å’Œæµ‹è¯•

### æ•°æ®åº“ä¼˜åŒ–
- [ ] åˆç†çš„è¡¨ç»“æ„è®¾è®¡
- [ ] ç´¢å¼•ç­–ç•¥ä¼˜åŒ–
- [ ] æŸ¥è¯¢æ€§èƒ½ä¼˜åŒ–
- [ ] äº‹åŠ¡å’Œè¿æ¥ç®¡ç†
- [ ] å¤‡ä»½æ¢å¤æœºåˆ¶

### ä»»åŠ¡è°ƒåº¦ç³»ç»Ÿ
- [ ] APScheduleré›†æˆ
- [ ] ä»»åŠ¡çŠ¶æ€ç›‘æ§
- [ ] å¤±è´¥é‡è¯•æœºåˆ¶
- [ ] å¹¶å‘æ§åˆ¶
- [ ] æ€§èƒ½ç›‘æ§

### å®‰å…¨æ€§ä¿éšœ
- [ ] è¾“å…¥éªŒè¯å’Œè¿‡æ»¤
- [ ] SQLæ³¨å…¥é˜²æŠ¤
- [ ] æ–‡ä»¶ä¸Šä¼ å®‰å…¨
- [ ] è®¤è¯æˆæƒ
- [ ] è®¿é—®æ§åˆ¶

### æ€§èƒ½ä¼˜åŒ–
- [ ] æ•°æ®åº“æŸ¥è¯¢ä¼˜åŒ–
- [ ] ç¼“å­˜ç­–ç•¥å®ç°
- [ ] å¼‚æ­¥å¤„ç†
- [ ] èµ„æºç›‘æ§
- [ ] å‹åŠ›æµ‹è¯•

### ç›‘æ§å’Œæ—¥å¿—
- [ ] ç»“æ„åŒ–æ—¥å¿—
- [ ] æ€§èƒ½ç›‘æ§
- [ ] é”™è¯¯è¿½è¸ª
- [ ] ç³»ç»Ÿç›‘æ§
- [ ] å‘Šè­¦æœºåˆ¶

---

*è¿™äº›å…³é”®è¯å’Œå®ç°æŒ‡å—å°†å¸®åŠ©æ‚¨æ„å»ºé«˜è´¨é‡ã€é«˜æ€§èƒ½çš„åç«¯æœåŠ¡ï¼Œç¡®ä¿ç³»ç»Ÿçš„ç¨³å®šæ€§å’Œå¯æ‰©å±•æ€§ã€‚* 